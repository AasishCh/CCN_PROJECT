# CCN_PROJECT - Group 9
# Team Members
* Aasish Chunduri
* Yaswanth Mareedu
* Govind Rahul Mathamsetti
* Manoj Kumar Reddy Janapala
# INTRODUCTION (Voice-to-Text)
Voice-to-text conversion is a technology that allows a computer to transcribe human speech into written text. The goal of a voice-to-text conversion project is to develop a system that can accurately transcribe spoken language into text in real-time. This technology has many applications, including accessibility for people with disabilities, and automated speech recognition for customer service and other applications. In a voice-to-text conversion project, the system typically employs a combination of machine learning algorithms and signal processing techniques to analyze speech and transcribe it into text. 
## Methodology:
### 1. Speech Signal Capture
The system will use system's microphone to capture the speech signal. The microphone will be used to take the input in .mp3 format and will use a few techniques to reduce the background noise.
### 2. Speech-to-Text Conversion:
Once the speech signal is received, the system will use natural language processing (NLP) techniques to transcribe the speech to text. The NLP engine will use a combination of acoustic and language models to analyze the speech and convert it to text.
### 3. Output and User Interface:
The final output will be displayed on the web application. The user interface will be designed to be user-friendly and intuitive, with features such as recording the speech and displaying the speech in the text format.

We are taking the following github repository as reference to implement our project.<br />
Link: https://github.com/fcakyon/pywhisper

# Architecture
We are planning to use client-server architecture.
# Project Plan based on two weeks iteration
## Iteration 1
* Familiarize ourself with the Streamlit and WebRTC technologies and identify the necessary components and dependencies for the project.
* Implement basic functionalities such as audio recording and converting it to the text.
* Conduct initial tests of the model to ensure that the audio recording and conversion to text are working correctly.
## Iteration 2
* Design the architecture of the system and create a rough prototype of the user interface.
* Conduct tests to evaluate the accuracy of the speech recognition algorithms.
* Make any necessary adjustments to the algorithms based on the results of the tests.
## Iteration 3
* Integrate speech recognition algorithms into the system to transcribe audio into text.
* Improve the user interface and add additional features if possible.

This is what we have planned for the next 6 weeks, soon we will update future iterations.
